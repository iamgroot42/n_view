{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout, Reshape\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import cv2\n",
    "import pdb\n",
    "import progressbar\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_views = 5\n",
    "datasets = ['australian', 'bupa', 'colic', 'diabetes', 'german', 'ionosphere', 'kr-vs-kp', 'tic-tac-toe', 'vote', 'wdbc']\n",
    "dataset = datasets[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithm:\n",
    "# Input: L, U, Learn\n",
    "# Output: H\n",
    "# 1. Partition L into (v_1, v_2, ..., v_n)\n",
    "# 2. Learn h_i on v_i using Learn\n",
    "# 3. while (one of h_i changes):\n",
    "# \t3.1 Q = []\n",
    "# \t3.2 for i in range(n):\n",
    "#         if majority on classifiers other than h_i has better accuracy on L: \n",
    "#             for u in U:\n",
    "#                 if more than 50% of classifiers other than h_i agree on u:\n",
    "#                     Q_i = Q_i Union {u, prediction(u)}\n",
    "# \t3.3 for i in range(n):\n",
    "#           Learn h_i on L Union q_i\n",
    "# 4. Output H = Majority Over h_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_n(L_x, lower_cap=3, upper_cap=6):\n",
    "    min_counts = []\n",
    "    clusters = []\n",
    "    for find_n in range(lower_cap, upper_cap+1):\n",
    "        kmeans = KMeans(n_clusters=find_n, random_state=0).fit_predict(L_x)\n",
    "        clusters.append(kmeans)\n",
    "        _, counts = np.unique(kmeans, return_counts=True)\n",
    "        min_counts.append(min(counts))\n",
    "    return lower_cap + np.argmax(min_counts), clusters[np.argmax(min_counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 16)\n",
      "(43, 16)\n",
      "(21, 16)\n"
     ]
    }
   ],
   "source": [
    "# 1. Partition L into (v_1, v_2, ..., v_n)\n",
    "ds = get_dataset(dataset, 0.7, 0.25)\n",
    "[L_x, L_y], U, [test_x, test_y] = ds.get_data()\n",
    "\n",
    "n_views, kmeans = find_optimal_n(L_x)\n",
    "\n",
    "V = []\n",
    "for ind in range(n_views):\n",
    "    left = int(ind * L_x.shape[0] / n_views)\n",
    "    right = int((ind+1) * L_x.shape[0] / n_views)\n",
    "    indices = np.where(kmeans == ind)\n",
    "    print L_x[indices].shape\n",
    "#     V.append([L_x[left:right], L_y[left:right]])\n",
    "    V.append([L_x[indices], L_y[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 7 samples\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 0s - loss: 0.8147 - acc: 0.5357 - val_loss: 0.6910 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s - loss: 0.8805 - acc: 0.5357 - val_loss: 0.6892 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s - loss: 0.7747 - acc: 0.6071 - val_loss: 0.6872 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s - loss: 0.8062 - acc: 0.6429 - val_loss: 0.6853 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s - loss: 0.7659 - acc: 0.6786 - val_loss: 0.6834 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s - loss: 0.7940 - acc: 0.6429 - val_loss: 0.6815 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s - loss: 0.8248 - acc: 0.5714 - val_loss: 0.6796 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s - loss: 0.8179 - acc: 0.7143 - val_loss: 0.6777 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s - loss: 0.7978 - acc: 0.7143 - val_loss: 0.6758 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s - loss: 0.8981 - acc: 0.5357 - val_loss: 0.6740 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s - loss: 0.7902 - acc: 0.6071 - val_loss: 0.6721 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s - loss: 0.7906 - acc: 0.6429 - val_loss: 0.6702 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s - loss: 0.8776 - acc: 0.5714 - val_loss: 0.6684 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s - loss: 0.7765 - acc: 0.6786 - val_loss: 0.6666 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s - loss: 0.7403 - acc: 0.7143 - val_loss: 0.6648 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s - loss: 0.8382 - acc: 0.5000 - val_loss: 0.6629 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s - loss: 0.8785 - acc: 0.6786 - val_loss: 0.6611 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s - loss: 0.7882 - acc: 0.7143 - val_loss: 0.6594 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s - loss: 0.6372 - acc: 0.7857 - val_loss: 0.6576 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s - loss: 0.7577 - acc: 0.7143 - val_loss: 0.6558 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s - loss: 0.9864 - acc: 0.5357 - val_loss: 0.6540 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s - loss: 0.7862 - acc: 0.6429 - val_loss: 0.6522 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s - loss: 0.6945 - acc: 0.7500 - val_loss: 0.6505 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s - loss: 0.8191 - acc: 0.6786 - val_loss: 0.6486 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s - loss: 0.8352 - acc: 0.6071 - val_loss: 0.6469 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s - loss: 0.6792 - acc: 0.7500 - val_loss: 0.6452 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s - loss: 0.8004 - acc: 0.6786 - val_loss: 0.6434 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s - loss: 0.7081 - acc: 0.7143 - val_loss: 0.6417 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s - loss: 0.8516 - acc: 0.6429 - val_loss: 0.6400 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s - loss: 0.6941 - acc: 0.7500 - val_loss: 0.6383 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s - loss: 0.7660 - acc: 0.6071 - val_loss: 0.6366 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s - loss: 0.6345 - acc: 0.6786 - val_loss: 0.6350 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s - loss: 0.6957 - acc: 0.7143 - val_loss: 0.6334 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s - loss: 0.8241 - acc: 0.6071 - val_loss: 0.6317 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s - loss: 0.7377 - acc: 0.7143 - val_loss: 0.6301 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s - loss: 0.7828 - acc: 0.6429 - val_loss: 0.6284 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s - loss: 0.9181 - acc: 0.5714 - val_loss: 0.6268 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s - loss: 0.7983 - acc: 0.7143 - val_loss: 0.6251 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s - loss: 0.8566 - acc: 0.6071 - val_loss: 0.6235 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s - loss: 0.8405 - acc: 0.5714 - val_loss: 0.6220 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s - loss: 0.7293 - acc: 0.6429 - val_loss: 0.6204 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s - loss: 0.7505 - acc: 0.6071 - val_loss: 0.6188 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s - loss: 0.8388 - acc: 0.6429 - val_loss: 0.6172 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s - loss: 0.8099 - acc: 0.5000 - val_loss: 0.6155 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s - loss: 0.8199 - acc: 0.6429 - val_loss: 0.6141 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s - loss: 0.7592 - acc: 0.6786 - val_loss: 0.6124 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s - loss: 0.7572 - acc: 0.6429 - val_loss: 0.6109 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s - loss: 0.7868 - acc: 0.5357 - val_loss: 0.6092 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s - loss: 0.8634 - acc: 0.5357 - val_loss: 0.6078 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s - loss: 0.9431 - acc: 0.5357 - val_loss: 0.6064 - val_acc: 1.0000\n",
      " 32/108 [=======>......................] - ETA: 0s[0.6115546579714175, 0.8703703725779498]\n",
      "Train on 34 samples, validate on 9 samples\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 0s - loss: 1.2452 - acc: 0.5000 - val_loss: 0.9260 - val_acc: 0.2222\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 0s - loss: 0.9873 - acc: 0.5882 - val_loss: 0.9210 - val_acc: 0.2222\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 0s - loss: 1.3278 - acc: 0.5000 - val_loss: 0.9118 - val_acc: 0.2222\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 0s - loss: 1.0262 - acc: 0.6471 - val_loss: 0.9025 - val_acc: 0.2222\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 0s - loss: 1.1488 - acc: 0.5882 - val_loss: 0.8964 - val_acc: 0.2222\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 0s - loss: 0.6478 - acc: 0.7059 - val_loss: 0.8943 - val_acc: 0.2222\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 0s - loss: 0.8638 - acc: 0.5000 - val_loss: 0.8897 - val_acc: 0.2222\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 0s - loss: 1.4141 - acc: 0.3529 - val_loss: 0.8844 - val_acc: 0.2222\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 0s - loss: 1.1818 - acc: 0.4412 - val_loss: 0.8779 - val_acc: 0.2222\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 0s - loss: 1.3271 - acc: 0.5588 - val_loss: 0.8709 - val_acc: 0.2222\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 0s - loss: 1.2215 - acc: 0.4706 - val_loss: 0.8643 - val_acc: 0.3333\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 0s - loss: 1.1992 - acc: 0.4706 - val_loss: 0.8605 - val_acc: 0.3333\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 0s - loss: 1.0399 - acc: 0.5588 - val_loss: 0.8564 - val_acc: 0.3333\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 0s - loss: 0.8181 - acc: 0.6176 - val_loss: 0.8516 - val_acc: 0.3333\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 0s - loss: 1.1443 - acc: 0.5294 - val_loss: 0.8453 - val_acc: 0.3333\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s - loss: 1.2251 - acc: 0.5294 - val_loss: 0.8412 - val_acc: 0.3333\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 0s - loss: 0.9244 - acc: 0.6471 - val_loss: 0.8346 - val_acc: 0.3333\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 0s - loss: 1.0115 - acc: 0.5000 - val_loss: 0.8288 - val_acc: 0.4444\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 0s - loss: 1.0866 - acc: 0.5882 - val_loss: 0.8276 - val_acc: 0.4444\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 0s - loss: 0.7659 - acc: 0.6471 - val_loss: 0.8214 - val_acc: 0.4444\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 0s - loss: 1.0484 - acc: 0.5882 - val_loss: 0.8171 - val_acc: 0.6667\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 0s - loss: 0.9957 - acc: 0.5588 - val_loss: 0.8131 - val_acc: 0.6667\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 0s - loss: 0.8422 - acc: 0.6471 - val_loss: 0.8106 - val_acc: 0.6667\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 0s - loss: 1.0499 - acc: 0.4118 - val_loss: 0.8061 - val_acc: 0.6667\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 0s - loss: 1.0441 - acc: 0.5000 - val_loss: 0.8018 - val_acc: 0.6667\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 0s - loss: 0.8796 - acc: 0.4412 - val_loss: 0.7999 - val_acc: 0.6667\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 0s - loss: 1.0717 - acc: 0.5000 - val_loss: 0.7950 - val_acc: 0.6667\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 0s - loss: 1.3048 - acc: 0.4412 - val_loss: 0.7923 - val_acc: 0.6667\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 0s - loss: 0.7680 - acc: 0.5588 - val_loss: 0.7907 - val_acc: 0.6667\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 0s - loss: 1.0949 - acc: 0.5588 - val_loss: 0.7876 - val_acc: 0.6667\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 0s - loss: 0.6617 - acc: 0.4706 - val_loss: 0.7851 - val_acc: 0.6667\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 0s - loss: 0.9208 - acc: 0.5588 - val_loss: 0.7820 - val_acc: 0.6667\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 0s - loss: 1.1537 - acc: 0.4706 - val_loss: 0.7799 - val_acc: 0.6667\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 0s - loss: 1.1454 - acc: 0.5000 - val_loss: 0.7745 - val_acc: 0.6667\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 0s - loss: 0.9657 - acc: 0.5882 - val_loss: 0.7719 - val_acc: 0.6667\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 0s - loss: 0.9469 - acc: 0.5000 - val_loss: 0.7684 - val_acc: 0.6667\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 0s - loss: 1.0768 - acc: 0.5588 - val_loss: 0.7639 - val_acc: 0.6667\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 0s - loss: 1.0622 - acc: 0.5588 - val_loss: 0.7623 - val_acc: 0.6667\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 0s - loss: 0.8022 - acc: 0.5588 - val_loss: 0.7611 - val_acc: 0.6667\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9822 - acc: 0.562 - 0s - loss: 0.9641 - acc: 0.5588 - val_loss: 0.7602 - val_acc: 0.6667\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 0s - loss: 0.8258 - acc: 0.6176 - val_loss: 0.7563 - val_acc: 0.6667\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 0s - loss: 0.9283 - acc: 0.5000 - val_loss: 0.7549 - val_acc: 0.6667\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 0s - loss: 1.0162 - acc: 0.5294 - val_loss: 0.7542 - val_acc: 0.6667\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 0s - loss: 0.9306 - acc: 0.6176 - val_loss: 0.7505 - val_acc: 0.6667\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 0s - loss: 0.8873 - acc: 0.6176 - val_loss: 0.7471 - val_acc: 0.5556\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 0s - loss: 0.9571 - acc: 0.5882 - val_loss: 0.7483 - val_acc: 0.5556\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 0s - loss: 1.0756 - acc: 0.5000 - val_loss: 0.7464 - val_acc: 0.5556\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 0s - loss: 0.7406 - acc: 0.6176 - val_loss: 0.7471 - val_acc: 0.5556\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 0s - loss: 0.8306 - acc: 0.6471 - val_loss: 0.7459 - val_acc: 0.5556\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 0s - loss: 0.9908 - acc: 0.4706 - val_loss: 0.7431 - val_acc: 0.5556\n",
      " 32/108 [=======>......................] - ETA: 0s[0.49278763819623878, 0.71296296737812181]\n",
      "Train on 16 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 0s - loss: 1.6668 - acc: 0.3750 - val_loss: 2.1039 - val_acc: 0.4000\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s - loss: 1.6647 - acc: 0.3750 - val_loss: 2.0976 - val_acc: 0.4000\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s - loss: 1.4530 - acc: 0.5000 - val_loss: 2.0878 - val_acc: 0.4000\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s - loss: 1.6280 - acc: 0.6250 - val_loss: 2.0777 - val_acc: 0.4000\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s - loss: 2.0176 - acc: 0.4375 - val_loss: 2.0699 - val_acc: 0.4000\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s - loss: 1.7000 - acc: 0.5625 - val_loss: 2.0552 - val_acc: 0.4000\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s - loss: 1.5155 - acc: 0.6250 - val_loss: 2.0477 - val_acc: 0.4000\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s - loss: 1.3536 - acc: 0.4375 - val_loss: 2.0411 - val_acc: 0.4000\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s - loss: 1.2087 - acc: 0.6875 - val_loss: 2.0339 - val_acc: 0.4000\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s - loss: 1.1335 - acc: 0.5625 - val_loss: 2.0266 - val_acc: 0.4000\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s - loss: 0.9665 - acc: 0.6250 - val_loss: 2.0214 - val_acc: 0.4000\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s - loss: 1.4553 - acc: 0.4375 - val_loss: 2.0140 - val_acc: 0.4000\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 0s - loss: 1.7301 - acc: 0.3750 - val_loss: 2.0021 - val_acc: 0.4000\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s - loss: 1.4481 - acc: 0.5625 - val_loss: 1.9954 - val_acc: 0.4000\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s - loss: 1.7058 - acc: 0.5625 - val_loss: 1.9868 - val_acc: 0.4000\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s - loss: 1.4633 - acc: 0.4375 - val_loss: 1.9816 - val_acc: 0.4000\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s - loss: 1.2412 - acc: 0.5625 - val_loss: 1.9743 - val_acc: 0.4000\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s - loss: 1.2402 - acc: 0.5625 - val_loss: 1.9692 - val_acc: 0.4000\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s - loss: 1.0758 - acc: 0.5000 - val_loss: 1.9646 - val_acc: 0.4000\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s - loss: 1.7769 - acc: 0.4375 - val_loss: 1.9584 - val_acc: 0.4000\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s - loss: 1.5514 - acc: 0.3750 - val_loss: 1.9502 - val_acc: 0.4000\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s - loss: 1.4125 - acc: 0.5625 - val_loss: 1.9450 - val_acc: 0.4000\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s - loss: 1.1354 - acc: 0.5625 - val_loss: 1.9370 - val_acc: 0.4000\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s - loss: 1.7571 - acc: 0.5625 - val_loss: 1.9294 - val_acc: 0.4000\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s - loss: 1.4482 - acc: 0.6875 - val_loss: 1.9194 - val_acc: 0.4000\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s - loss: 0.8875 - acc: 0.6250 - val_loss: 1.9131 - val_acc: 0.4000\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s - loss: 0.6061 - acc: 0.8125 - val_loss: 1.9082 - val_acc: 0.4000\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s - loss: 1.4917 - acc: 0.5000 - val_loss: 1.9023 - val_acc: 0.4000\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s - loss: 1.8001 - acc: 0.6250 - val_loss: 1.8939 - val_acc: 0.4000\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s - loss: 1.9705 - acc: 0.4375 - val_loss: 1.8869 - val_acc: 0.4000\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s - loss: 0.8809 - acc: 0.5625 - val_loss: 1.8809 - val_acc: 0.4000\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s - loss: 1.3775 - acc: 0.5000 - val_loss: 1.8768 - val_acc: 0.4000\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s - loss: 1.5862 - acc: 0.4375 - val_loss: 1.8722 - val_acc: 0.4000\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s - loss: 1.4260 - acc: 0.4375 - val_loss: 1.8616 - val_acc: 0.4000\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s - loss: 1.2729 - acc: 0.5000 - val_loss: 1.8555 - val_acc: 0.4000\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s - loss: 1.2003 - acc: 0.8125 - val_loss: 1.8505 - val_acc: 0.4000\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s - loss: 1.4541 - acc: 0.5625 - val_loss: 1.8470 - val_acc: 0.4000\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s - loss: 1.8956 - acc: 0.6250 - val_loss: 1.8372 - val_acc: 0.4000\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s - loss: 1.4448 - acc: 0.5000 - val_loss: 1.8302 - val_acc: 0.4000\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s - loss: 0.8703 - acc: 0.5625 - val_loss: 1.8273 - val_acc: 0.4000\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s - loss: 1.2281 - acc: 0.5625 - val_loss: 1.8251 - val_acc: 0.4000\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s - loss: 0.8772 - acc: 0.5000 - val_loss: 1.8214 - val_acc: 0.4000\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s - loss: 2.0632 - acc: 0.3125 - val_loss: 1.8134 - val_acc: 0.4000\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s - loss: 1.1713 - acc: 0.6250 - val_loss: 1.8095 - val_acc: 0.4000\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s - loss: 1.2530 - acc: 0.5000 - val_loss: 1.8049 - val_acc: 0.4000\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s - loss: 0.9801 - acc: 0.7500 - val_loss: 1.7993 - val_acc: 0.4000\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s - loss: 1.0766 - acc: 0.6875 - val_loss: 1.7942 - val_acc: 0.4000\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s - loss: 1.4668 - acc: 0.5000 - val_loss: 1.7914 - val_acc: 0.4000\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s - loss: 1.2298 - acc: 0.5625 - val_loss: 1.7848 - val_acc: 0.4000\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s - loss: 0.9466 - acc: 0.6875 - val_loss: 1.7782 - val_acc: 0.4000\n",
      " 32/108 [=======>......................] - ETA: 0s[1.5993290212419298, 0.22222222222222221]\n"
     ]
    }
   ],
   "source": [
    "# 2. Learn h_i on v_i using Learn\n",
    "H = []\n",
    "n_attr = V[ind][0].shape[1]\n",
    "\n",
    "for ind in range(n_views):\n",
    "    h = Sequential()\n",
    "    h.add(Dense(input_shape=(n_attr,), units=n_attr / 2))\n",
    "    h.add(Activation('relu'))\n",
    "    h.add(BatchNormalization())\n",
    "    h.add(Dense(units=n_attr/5))\n",
    "    h.add(Activation('relu'))\n",
    "    h.add(BatchNormalization())\n",
    "    h.add(Dropout(0.5))\n",
    "    h.add(Dense(units=V[ind][1].shape[1]))\n",
    "    h.add(Activation('softmax'))\n",
    "    h.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
    "    H.append(h)\n",
    "\n",
    "for ind in range(n_views):\n",
    "    H[ind].fit(V[ind][0], V[ind][1], epochs=50, batch_size=32, validation_split=0.2, verbose=True)\n",
    "    print H[ind].evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:66: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "changed = True\n",
    "to_plot = []\n",
    "num_runs = 0\n",
    "while (changed and num_runs <= 10):\n",
    "    print num_runs\n",
    "    preds_L = []\n",
    "    for ind in range(n_views):\n",
    "        preds_L.append(H[ind].predict(L_x))\n",
    "    preds_L = np.array(preds_L)\n",
    "    preds_L = np.argmax(preds_L, axis=2)\n",
    "    \n",
    "    preds_U = []\n",
    "    for ind in range(n_views):\n",
    "        preds_U.append(H[ind].predict(U))\n",
    "    preds_U = np.array(preds_U)\n",
    "    preds_U = np.argmax(preds_U, axis=2)\n",
    "    \n",
    "    perfs = []\n",
    "    test_preds = []\n",
    "    for ind in range(n_views):\n",
    "        test_preds.append(np.argmax(H[ind].predict(test_x), axis=1))\n",
    "    test_preds = np.array(test_preds)\n",
    "    \n",
    "    for ind in range(n_views):\n",
    "        perf = accuracy_score(np.argmax(test_y, axis=1), test_preds[ind])\n",
    "        perfs.append(perf)\n",
    "    perfs.append(accuracy_score(np.argmax(test_y, axis=1),\n",
    "                                np.reshape(stats.mode(test_preds, axis=0)[0], (-1,))))\n",
    "    to_plot.append(perfs)\n",
    "    \n",
    "    Q = []\n",
    "    update = [False for _ in range(n_views)]\n",
    "    for cur in range(n_views):\n",
    "        elems_take = [view_ind for view_ind in range(n_views) if view_ind != cur]\n",
    "        preds_others_L = preds_L[elems_take]\n",
    "        preds_others_U = preds_U[elems_take]\n",
    "        \n",
    "        acc_others_L = accuracy_score(np.argmax(L_y, axis=1), \n",
    "                                      np.reshape(stats.mode(preds_others_L, axis=0)[0], (-1,)))\n",
    "        acc_cur_L = accuracy_score(np.argmax(L_y,axis=1), preds_L[cur])\n",
    "        q_cur = [[], []]\n",
    "        if acc_others_L > acc_cur_L:\n",
    "            update[cur] = True\n",
    "            for u_ind in range(preds_U.shape[1]):\n",
    "                mode_prediction = stats.mode(preds_others_U[:, u_ind])[0][0]\n",
    "                if np.sum(preds_others_U[:, u_ind] == mode_prediction) >= 0.5 * (n_views - 1):\n",
    "                    q_cur[0].append(U[u_ind])\n",
    "                    label_temp = [0, 0]; label_temp[mode_prediction] = 1\n",
    "                    q_cur[1].append(label_temp)\n",
    "        Q.append([np.array(q_cur[0]), np.array(q_cur[1])])\n",
    "    for cur in range(n_views):\n",
    "        if update[cur]:\n",
    "            comb_x = np.concatenate([L_x, Q[cur][0]], axis=0)\n",
    "            comb_y = np.concatenate([L_y, Q[cur][1]], axis=0)\n",
    "            H[cur].fit(comb_x, comb_y, epochs=20, batch_size=32, validation_split=0.2, verbose=False)\n",
    "    \n",
    "    preds_L_new = []\n",
    "    for ind in range(n_views):\n",
    "        preds_L_new.append(H[ind].predict(L_x))\n",
    "    \n",
    "    preds_U_new = []\n",
    "    for ind in range(n_views):\n",
    "        preds_U_new.append(H[ind].predict(U))\n",
    "    \n",
    "    same = (preds_L == preds_L_new) and (preds_U == preds_U_new)\n",
    "    changed = not same\n",
    "    num_runs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAG5CAYAAACgKh/DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d12519850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.clf()\n",
    "handles = []\n",
    "labels = []\n",
    "for ind in range(n_views):\n",
    "    ys = [x[ind] for x in to_plot]\n",
    "    handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = str(ind))\n",
    "    handles.append(handle)\n",
    "    labels.append('Classifier %d' % ind)\n",
    "ys = [x[n_views] for x in to_plot]\n",
    "handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = 'Overall')\n",
    "handles.append(handle)\n",
    "labels.append('Max Voting')\n",
    "\n",
    "plt.legend(handles, labels, bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "# plt.legend(handles, labels)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Iterations vs accuracy for Dataset: %s' % dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
