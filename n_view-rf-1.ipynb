{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout, Reshape\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.cluster import KMeans,DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import cv2\n",
    "import progressbar\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_views = 4\n",
    "datasets = ['australian', 'bupa', 'colic', 'diabetes', 'german', 'ionosphere', 'kr-vs-kp', 'tic-tac-toe', 'vote', 'wdbc']\n",
    "dataset = datasets[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_n(L_x, noise_threshold=10, lower_cap=3, upper_cap=8):\n",
    "    min_counts = []\n",
    "    clusters = []\n",
    "    for find_n in range(lower_cap, upper_cap+1):\n",
    "        kmeans = AgglomerativeClustering(n_clusters=find_n).fit_predict(L_x)\n",
    "        temp = []\n",
    "        new_km = []\n",
    "        _, counts = np.unique(kmeans, return_counts=True)\n",
    "        print counts\n",
    "        for i in range(len(counts)):\n",
    "            if counts[i] > noise_threshold:\n",
    "                temp.append(counts[i])\n",
    "                new_km.append(np.where(kmeans==i)[0])\n",
    "        min_counts.append(min(temp))\n",
    "        print find_n, \"gets\", len(new_km)\n",
    "        clusters.append(new_km)\n",
    "    print \"selected\", np.argmax(min_counts), \"with\", len(clusters[np.argmax(min_counts)])\n",
    "    return clusters[np.argmax(min_counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Partition L into (v_1, v_2, ..., v_n)\n",
    "def get_dset(dataset):\n",
    "    global n_views\n",
    "    ds = get_dataset(dataset, 0.7, 0.25)\n",
    "    [L_x, L_y], U, [test_x, test_y] = ds.get_data()\n",
    "    L_y = np.argmax(L_y, axis=1)\n",
    "    test_y = np.argmax(test_y, axis=1)\n",
    "    kmeans = find_optimal_n(L_x)\n",
    "    n_views = len(kmeans)\n",
    "    V = []\n",
    "    for ind in range(n_views):\n",
    "        indices = kmeans[ind]\n",
    "        V.append([L_x[indices], L_y[indices]])\n",
    "    return ds, [L_x, L_y], U, [test_x, test_y], V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Learn h_i on v_i using Learn\n",
    "def get_classifiers(ds, L_x, L_y, U, test_x, test_y, V):\n",
    "    H = []\n",
    "    n_attr = V[0][0].shape[1]\n",
    "\n",
    "    classifiers = [RandomForestClassifier(max_depth=2, random_state=0)\n",
    "                   ,AdaBoostClassifier(),\n",
    "                   GradientBoostingClassifier(),\n",
    "                   KNeighborsClassifier()\n",
    "                   ,MLPClassifier()]\n",
    "    \n",
    "    for ind in range(n_views):\n",
    "        h = classifiers[ind]\n",
    "        H.append(h)\n",
    "\n",
    "    for ind in range(n_views):\n",
    "        H[ind].fit(V[ind][0], V[ind][1])\n",
    "        print accuracy_score(test_y, H[ind].predict(test_x))\n",
    "    \n",
    "    return H, n_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "def cotrain(ds, L_x, L_y, U, test_x, test_y, V, H, n_attr):\n",
    "    changed = True\n",
    "    to_plot = []\n",
    "    num_runs = 5\n",
    "    while (changed and num_runs <= 10):\n",
    "        print num_runs\n",
    "        preds_L = []\n",
    "        for ind in range(n_views):\n",
    "            preds_L.append(H[ind].predict(L_x))\n",
    "        preds_L = np.array(preds_L)\n",
    "        # preds_L = np.argmax(preds_L, axis=2)\n",
    "\n",
    "        preds_U = []\n",
    "        for ind in range(n_views):\n",
    "            preds_U.append(H[ind].predict(U))\n",
    "        preds_U = np.array(preds_U)\n",
    "        # preds_U = np.argmax(preds_U, axis=2)\n",
    "\n",
    "        perfs = []\n",
    "        test_preds = []\n",
    "        for ind in range(n_views):\n",
    "            test_preds.append(H[ind].predict(test_x))\n",
    "        test_preds = np.array(test_preds)\n",
    "\n",
    "        for ind in range(n_views):\n",
    "            perf = accuracy_score(test_y, test_preds[ind])\n",
    "            perfs.append(perf)\n",
    "        perfs.append(accuracy_score(test_y,\n",
    "                                    np.reshape(stats.mode(test_preds, axis=0)[0], (-1,))))\n",
    "        to_plot.append(perfs)\n",
    "\n",
    "        Q = []\n",
    "        update = [False for _ in range(n_views)]\n",
    "        for cur in range(n_views):\n",
    "            elems_take = [view_ind for view_ind in range(n_views) if view_ind != cur]\n",
    "            preds_others_L = preds_L[elems_take]\n",
    "            preds_others_U = preds_U[elems_take]\n",
    "            # pdb.set_trace()\n",
    "            acc_others_L = accuracy_score(L_y, \n",
    "                                          np.reshape(stats.mode(preds_others_L, axis=0)[0], (-1,)))\n",
    "            acc_cur_L = accuracy_score(L_y, preds_L[cur])\n",
    "            q_cur = [[], []]\n",
    "            if acc_others_L > acc_cur_L:\n",
    "                update[cur] = True\n",
    "                for u_ind in range(preds_U.shape[1]):\n",
    "                    mode_prediction = stats.mode(preds_others_U[:, u_ind])[0][0]\n",
    "                    if np.sum(preds_others_U[:, u_ind] == mode_prediction) >= 0.5 * (n_views - 1):\n",
    "                        q_cur[0].append(U[u_ind])\n",
    "                        label_temp = mode_prediction\n",
    "                        q_cur[1].append(label_temp)\n",
    "            Q.append([np.array(q_cur[0]), np.array(q_cur[1])])\n",
    "        for cur in range(n_views):\n",
    "            if update[cur]:\n",
    "                comb_x = np.concatenate([L_x, Q[cur][0]], axis=0)\n",
    "                comb_y = np.concatenate([L_y, Q[cur][1]], axis=0)\n",
    "                H[cur].fit(comb_x, comb_y)\n",
    "\n",
    "        preds_L_new = []\n",
    "        for ind in range(n_views):\n",
    "            preds_L_new.append(H[ind].predict(L_x))\n",
    "\n",
    "        preds_U_new = []\n",
    "        for ind in range(n_views):\n",
    "            preds_U_new.append(H[ind].predict(U))\n",
    "\n",
    "        same = np.array_equal(preds_L, np.array(preds_L_new)) and np.array_equal(preds_U, np.array(preds_U_new))\n",
    "        changed = not same\n",
    "        num_runs += 1\n",
    "    return to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(to_plot, n_views, dset):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.clf()\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for ind in range(n_views):\n",
    "        ys = [x[ind] for x in to_plot]\n",
    "        handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = str(ind))\n",
    "        handles.append(handle)\n",
    "        labels.append('Classifier %d' % ind)\n",
    "    ys = [x[n_views] for x in to_plot]\n",
    "    handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = 'Overall')\n",
    "    handles.append(handle)\n",
    "    labels.append('Max Voting')\n",
    "\n",
    "    plt.legend(handles, labels, bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    # plt.legend(handles, labels)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Iterations vs accuracy for Dataset: %s' % dset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153   1   3]\n",
      "3 gets 1\n",
      "[ 14 139   3   1]\n",
      "4 gets 2\n",
      "[  3 139   6   1   8]\n",
      "5 gets 1\n",
      "[139   8   6   1   2   1]\n",
      "6 gets 1\n",
      "[112   8  27   1   2   1   6]\n",
      "7 gets 2\n",
      "[111   8  27   1   2   1   6   1]\n",
      "8 gets 2\n",
      "selected 0 with 1\n",
      "(157, 14) (157,) australian 1\n",
      "0.877192982456\n",
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [157, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-4ce24f178645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mL_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_views\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mto_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcotrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_views\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-243-f06fba0eb8ff>\u001b[0m in \u001b[0;36mcotrain\u001b[0;34m(ds, L_x, L_y, U, test_x, test_y, V, H, n_attr)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             acc_others_L = accuracy_score(L_y, \n\u001b[0;32m---> 41\u001b[0;31m                                           np.reshape(stats.mode(preds_others_L, axis=0)[0], (-1,)))\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0macc_cur_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_L\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mq_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 204\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [157, 0]"
     ]
    }
   ],
   "source": [
    "for dset in ['australian', 'bupa', 'colic', 'diabetes', 'german', 'ionosphere', 'kr-vs-kp', 'tic-tac-toe', 'vote', 'wdbc']:\n",
    "    ds, [L_x, L_y], U, [test_x, test_y], V = get_dset(dset)\n",
    "    print L_x.shape, L_y.shape, dset, n_views\n",
    "    H, n_attr = get_classifiers(ds, L_x, L_y, U, test_x, test_y, V)\n",
    "    to_plot = cotrain(ds, L_x, L_y, U, test_x, test_y, V, H, n_attr)\n",
    "    plot(to_plot, n_views, dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
