{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, BatchNormalization, Dropout, Reshape\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import cv2\n",
    "import pdb\n",
    "import progressbar\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_views = 3\n",
    "datasets = ['australian', 'bupa', 'colic', 'diabetes', 'german', 'ionosphere', 'kr-vs-kp', 'tic-tac-toe', 'vote', 'wdbc']\n",
    "dataset = datasets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_n(L_x, lower_cap=3, upper_cap=6):\n",
    "    min_counts = []\n",
    "    clusters = []\n",
    "    for find_n in range(lower_cap, upper_cap+1):\n",
    "        kmeans = KMeans(n_clusters=find_n, random_state=0).fit_predict(L_x)\n",
    "        clusters.append(kmeans)\n",
    "        _, counts = np.unique(kmeans, return_counts=True)\n",
    "        min_counts.append(min(counts))\n",
    "    return lower_cap + np.argmax(min_counts), clusters[np.argmax(min_counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Partition L into (v_1, v_2, ..., v_n)\n",
    "def get_dset(dataset):\n",
    "    ds = get_dataset(dataset, 0.7, 0.25)\n",
    "    [L_x, L_y], U, [test_x, test_y] = ds.get_data()\n",
    "#     L_y = np.argmax(L_y, axis=1)\n",
    "#     test_y = np.argmax(test_y, axis=1)\n",
    "    \n",
    "    V = []\n",
    "    kmeans = KMeans(n_clusters=n_views, random_state=0).fit_predict(L_x)\n",
    "    for ind in range(n_views):\n",
    "        indices = np.where(kmeans == ind)\n",
    "        print L_y[indices].shape\n",
    "        V.append([L_x[indices], L_y[indices]])\n",
    "    return ds, [L_x, L_y], U, [test_x, test_y], V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Learn h_i on v_i using Learn\n",
    "def get_classifiers(ds, L_x, L_y, U, test_x, test_y, V):\n",
    "    H = []\n",
    "    n_attr = V[0][0].shape[1]\n",
    "\n",
    "    classifiers = [RandomForestClassifier(max_depth=2, random_state=0)\n",
    "                   ,AdaBoostClassifier(),\n",
    "                   GradientBoostingClassifier(),\n",
    "                   KNeighborsClassifier()\n",
    "                   ,MLPClassifier()]\n",
    "    \n",
    "    for ind in range(n_views):\n",
    "        h = classifiers[ind]\n",
    "        H.append(h)\n",
    "\n",
    "    for ind in range(n_views):\n",
    "        H[ind].fit(V[ind][0], np.argmax(V[ind][1],axis=1))\n",
    "        print accuracy_score(np.argmax(test_y,axis=1), H[ind].predict(test_x))\n",
    "    \n",
    "    return H, n_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3\n",
    "def cotrain(ds, L_x, L_y, U, test_x, test_y, V, H, n_attr):\n",
    "    changed = True\n",
    "    to_plot = []\n",
    "    num_runs = 5\n",
    "    while (changed and num_runs <= 10):\n",
    "        print num_runs\n",
    "        preds_L = []\n",
    "        for ind in range(n_views):\n",
    "            preds_L.append(H[ind].predict_proba(L_x))\n",
    "        preds_L = np.array(preds_L)\n",
    "        # preds_L = np.argmax(preds_L, axis=2)\n",
    "\n",
    "        preds_U = []\n",
    "        for ind in range(n_views):\n",
    "            preds_U.append(H[ind].predict_proba(U))\n",
    "        preds_U = np.array(preds_U)\n",
    "        # preds_U = np.argmax(preds_U, axis=2)\n",
    "\n",
    "        perfs = []\n",
    "        test_preds = []\n",
    "        for ind in range(n_views):\n",
    "            test_preds.append(H[ind].predict_proba(test_x))\n",
    "        test_preds = np.array(test_preds)\n",
    "    \n",
    "        for ind in range(n_views):\n",
    "            perf = accuracy_score(np.argmax(test_y, axis=1), np.argmax(test_preds[ind], axis=1))\n",
    "            perfs.append(perf)\n",
    "        perfs.append(accuracy_score(np.argmax(test_y, axis=1),\n",
    "                                np.argmax(np.sum(test_preds, axis=0), axis=1)))\n",
    "        to_plot.append(perfs)\n",
    "\n",
    "        Q = []\n",
    "        update = [False for _ in range(n_views)]\n",
    "        for cur in range(n_views):\n",
    "            elems_take = [view_ind for view_ind in range(n_views) if view_ind != cur]\n",
    "            preds_others_L = preds_L[elems_take]\n",
    "            preds_others_U = preds_U[elems_take]\n",
    "            # pdb.set_trace()\n",
    "            acc_others_L = accuracy_score(np.argmax(L_y, axis=1), \n",
    "                                      np.argmax(np.sum(preds_others_L, axis=0), axis=1))\n",
    "            acc_cur_L = accuracy_score(np.argmax(L_y, axis=1), np.argmax(preds_L[cur], axis=1))\n",
    "            q_cur = [[], []]\n",
    "            if acc_others_L > acc_cur_L:\n",
    "                update[cur] = True\n",
    "                for u_ind in range(preds_U.shape[1]):\n",
    "                    sum_prediction = np.argmax(np.sum(preds_others_U[:, u_ind], axis=0))\n",
    "                    if np.sum(np.argmax(preds_others_U[:, u_ind], axis=1) == sum_prediction) >= 0.5 * (n_views - 1):\n",
    "                        q_cur[0].append(U[u_ind])\n",
    "                        label_temp = [0, 0]; label_temp[sum_prediction] = 1\n",
    "                        q_cur[1].append(label_temp)\n",
    "            Q.append([np.array(q_cur[0]), np.array(q_cur[1])])\n",
    "        for cur in range(n_views):\n",
    "            if update[cur]:\n",
    "                comb_x = np.concatenate([L_x, Q[cur][0]], axis=0)\n",
    "                comb_y = np.concatenate([L_y, Q[cur][1]], axis=0)\n",
    "                H[cur].fit(comb_x, np.argmax(comb_y,axis=1))\n",
    "\n",
    "        preds_L_new = []\n",
    "        for ind in range(n_views):\n",
    "            preds_L_new.append(H[ind].predict_proba(L_x))\n",
    "\n",
    "        preds_U_new = []\n",
    "        for ind in range(n_views):\n",
    "            preds_U_new.append(H[ind].predict_proba(U))\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        same = np.array_equal(preds_L, np.array(preds_L_new)) and np.array_equal(preds_U, np.array(preds_U_new))\n",
    "        changed = not same\n",
    "        num_runs += 1\n",
    "    return to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(to_plot, n_views, dset):\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.clf()\n",
    "    handles = []\n",
    "    labels = []\n",
    "    for ind in range(n_views):\n",
    "        ys = [x[ind] for x in to_plot]\n",
    "        handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = str(ind))\n",
    "        handles.append(handle)\n",
    "        labels.append('Classifier %d' % ind)\n",
    "    ys = [x[n_views] for x in to_plot]\n",
    "    handle, = plt.plot(range(len(to_plot)), ys, marker='o', label = 'Overall')\n",
    "    handles.append(handle)\n",
    "    labels.append('Probability sum based')\n",
    "\n",
    "    plt.legend(handles, labels, bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    # plt.legend(handles, labels)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Iterations vs accuracy for Dataset: %s' % dset)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "(7, 2)\n",
      "(140, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-590859c7dc9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'australian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bupa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'colic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diabetes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'german'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ionosphere'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kr-vs-kp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tic-tac-toe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vote'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wdbc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mL_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mto_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcotrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_views\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-541b75e1e7f4>\u001b[0m in \u001b[0;36mget_classifiers\u001b[0;34m(ds, L_x, L_y, U, test_x, test_y, V)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "for dset in ['australian', 'bupa', 'colic', 'diabetes', 'german', 'ionosphere', 'kr-vs-kp', 'tic-tac-toe', 'vote', 'wdbc']:\n",
    "    ds, [L_x, L_y], U, [test_x, test_y], V = get_dset(dset)\n",
    "    H, n_attr = get_classifiers(ds, L_x, L_y, U, test_x, test_y, V)\n",
    "    to_plot = cotrain(ds, L_x, L_y, U, test_x, test_y, V, H, n_attr)\n",
    "    plot(to_plot, n_views, dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
